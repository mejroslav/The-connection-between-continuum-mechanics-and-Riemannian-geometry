\chapter{Appendix}


In this chapter, we shall revise some basic definitions and propositions of the functional calculus which we will need for the proper formulation of the hydrodynamic geometry. 

Over the last century, modern mathematics has worked to develop the theory of generalized functions - distributions, including Dirac's delta distributions and operations with them. For the reader who seeks a nice introduction to this theory accompanied with several physical applications, we would recommend the book by R.P.Kanwal \cite{Kanwal}. The same applies to functional variations and the conditions under which they exist. A book written with a deep pedagogical attention on this topic is e.g. the university text by von Brunt \cite{Brunt}.
Physicists, however, operate with delta distributions as they would with "ordinary" functions, using dualities as integrals and functional variations as ordinary derivatives.


After introducing the concept of Gateaux and Frechet derivatives which are suitable for arbitrary normed space we shall take a closer look on the space of smooth functions and functionals on it.

\section{Functional derivatives}

\todo[inline]{přidat nějaký kontext}

\begin{definition}[Gateaux and Frechet derivative]
    Let $X$ be a normed space, $A: X \to \R$ a functional and $x \in \Dom(A)$.
    \begin{enumerate}
        \item Let $h \in D(A)$. Gateaux derivative $\delta A(x,h)$ in the direction $h$ is defined as
        \begin{align}
            \delta A (x,h) \coloneqq \der{}{t} A(x+th) |_{t=0} = \lim_{t \rightarrow 0} \frac{A(x+th)-A(x)}{t} \:.
        \end{align}

        \item Fréchet diferential $\DD_x A$ is defined as the unique linear bounded functional satisfying the relation
        \begin{align}
            \lim_{\norm{h} \rightarrow 0} \frac{A(x+h)-A(x)- \DD_x A(h)}{\norm{h}} = 0 \:.
        \end{align}
    \end{enumerate}
\end{definition}

We are intersted in such functionals, where $X$ is the space of smooth functions with the appropriate boundary conditions. The smoothness is required because the functionals would operate with derivatives, and the values beeing zero on the boundary is required because we shall use integration by parts.

One of possible choices is to take
\begin{align}
    X^k \coloneqq \set{f \in C^k(\Omega) \,|\, \DD^\alpha f = 0 \text{ on } \partial \Omega \text{ for } |\alpha| = 1, \cdots, k-1 } \:.
\end{align}
This space can be equipped with the usual supremum norm
\begin{align}
    \norm{f}_k \coloneqq \sum_{|\alpha| \leq k} \sup_{x \in \Omega} |\DD^\alpha f(x)| \:.
\end{align}
There are two main types of functionals on these spaces -  the integral functionals and Dirac's delta distributions.

\subsection{Integral functionals}

The first type is the integral functional
\begin{align}
    A[u] = \int_\Omega a(x,u(x),u'(x),\cdots,u^{(k)}(x)) \, \D^n x \:, \label{eq:integral-functional}
\end{align}
where $a : \R \times \R^{k} \to \R$ is an analytic function.
For simplicity we often write this using a physicist's notation
\begin{align}
    A[u] = \int a(u) \, \D^n x \:,
\end{align}
meaning that $a(u)$ is in fact function $a(x,u(x),u'(x),\cdots, u^{(k)}(x))$ and also the domain $\Omega$ is specified by the context. We call $a(u)$ the density of functional $A[u]$.

Gateaux derivative of $A$ is computed as follows:
\begin{align}
    \delta A[u,h] = \int_\Omega \sum_{i=1}^k \pder{a}{u^{(i)}}(x) h^{(i)}(x) \, \D^n x \:. \label{eq:Gateaux}
\end{align}
The functional $\delta A[u,h]$ is linear and bounded in $h$, so the Fréchet derivative of $A$ exists and is given by
\begin{align}
    \DD_u A [h] = \delta A[u,h] \:.
\end{align}
To eliminate the derivatives of $h(x)$ in \eqref{eq:Gateaux} we use integration by parts in each term of the sum (exploiting the fact that boundary terms are zero), obtaining
\begin{align}
    \DD_u A [h] = \int_\Omega \left[ \pder{a}{u}(x) - \der{}{x} \pder{a}{u'}(x) + \cdots + (-1)^k \der{^k}{x^k} \pder{a}{u^{(k)}}(x) \right] h(x) \, \D^n x \:. \label{eq:perpartes}
\end{align}

It is natural to give a special name to the integrand in \eqref{eq:perpartes}.

\begin{definition}[Functional derivative of the integral functional]
    Let $A$ be the integral functional given by \eqref{eq:integral-functional}. The functional derivative of $A$ is the function
    \begin{align}
        \fder{A}{u(x)} = \pder{a}{u}(x) - \der{}{x} \pder{a}{u'}(x) + \der{^2}{x^2} \pder{a}{u''} - \cdots + (-1)^k \der{^k}{x^k} \pder{a}{u^{(k)}}(x) \:.
    \end{align}
\end{definition}

The functional derivative can be seen as the density of the integral functional $\DD_u A$ applied on $h$: 
\begin{align}
    \DD_u A[h] = \int_\Omega \fder{A}{u(x)} h(x) \, \D x \:.
\end{align}
Since the Fréchet derivative is always linear bounded functional, another way to look at this relation is the following: $\DD_u A$ is a regular distribution represented by some smooth function $\fder{A}{u(x)}$, i.e.
\begin{align}
    \DD_u A[h] = \dual{T_{\fder{A}{u(x)}}}{h(x)} \:.
\end{align}

It follows from theory \cite{Brunt} that the functional derivative beeing zero is a necessery condition for the function beeing the extremal point of the functional (given that the corresponding function is smooth enough).

\begin{theorem}[Euler-Lagrange equations]
    Let $v \in C^\infty(\Omega)$ such that $v(x)$ is stationary point of the functional $A$ in \eqref{eq:integral-functional}, i.e
    \begin{align}
        \delta A[v,h] = 0 \:.
    \end{align}
    Then  
    \begin{align}
        \fder{A}{v(x)} = 0 \:.
    \end{align}
\end{theorem}

The computation above gives meaning to the 
\begin{align}
    A[u+h] = A[u] + \dual{\fder{A}{u}}{h} + o(h)\:,
\end{align}
where
\begin{align}
    \lim_{\norm{h} \rightarrow 0} \frac{o(h)}{\norm{h}} = 0 \:.
\end{align}
In physicist's notation, the function $h$ is often denoted as $\delta u$.


\subsection{Distributions}

\begin{definition}[Distributions]
    Let $\test(\Omega)$ be the space of smooth functions with compact support in $\Omega \subseteq \R^n$. The space of distributions $\dis(\Omega)$ is the dual space, i.e. the space of bounded linear functionals on $\test(\Omega)$. An element $T \in \dis(\Omega)$ is called a distribution.
\end{definition}

\begin{definition}[Regular distribution]
    Let $a \in L^1_{\text{loc}}(\Omega)$. A regular distribution is a distribution $T_a \in \dis(\Omega)$ defined as
    \begin{align}
        \dual{T_a}{\phi(x)} = \int_\Omega a(x) \phi(x) \D^n x \:.
    \end{align}
\end{definition}

Note that if two regular distributions satisfy $T_a = T_b$, then $a=b$ almost everywhere and vice versa.

\begin{definition}[Dirac delta distribution]
    Let $y \in \Omega$. The Dirac delta distribution $\delta(x-y)$ is defined as
    \begin{align}
        \dual{\delta(x-y)}{\phi(x)} = \phi(y) \:. 
    \end{align}
\end{definition}

\begin{definition}[Derivatives of distributions]
    Let $T \in \dis(\Omega)$ be a distribution. We define its derivative by
    \begin{align}
        \dual{D^\alpha T}{\phi} = (-1)^{|\alpha|} \dual{T}{D^\alpha \phi} \:,
    \end{align}
    where $\alpha$ is a multiindex and
    \begin{align}
        D^\alpha f = \frac{\partial^{|\alpha|} f}{\partial x_1^{\alpha_1} \partial x_2^{\alpha_2} \cdots \partial x^{\alpha_N}_N} \:.
    \end{align}
\end{definition}

The reason, why distributions have such a "nice" behaviour and are often used by mathematicians, is that every distribution is diferentiable infinitely many times. However, if we abandon this property and require only the existence of derivatives of the $k$-th order, we can extend regular and Dirac distributions on previously defined space $X^k$. Indeed,
\begin{align}
    | \dual{\partial_x^n \delta(x-y)}{f(x)} | \leq \norm{f}_n \quad \forall n = 0,1,\cdots, k\:,
\end{align}
so Dirac distributions and their derivatives are also bounded linear functionals on $X^k$ up to the order $k$.

Let $a \in C^\infty(\Omega)$. Then it makes sense to define the product of $a$ and arbitrary distribution $T$ by
\begin{align}
    \dual{a T}{\phi} = \dual{T}{a \phi} \:.
\end{align}

In the next chapter we shall frequently use the following identities of the delta distributions, which are written in the next lemma and which we will refer to as the Dirac identities.

\begin{lemma}[Dirac identities] \label{lemma:delta}
    \begin{align}
        f(y) \delta (x-y) =& f(x) \delta(x-y) \:, \\
        f(y) \partial_x \delta(x-y) =& f(x) \partial_x \delta(x-y) + f'(x) \delta(x-y) \:.
    \end{align}
\end{lemma}
\begin{proof}
    The first relation is trivial.
    Direct calculation gives
    \begin{align*}
        \dual{f(x) \partial_x \delta(x-y)}{\psi(x)} 
        =& \dual{\partial_x \delta(x-y)}{f(x) \psi(x)} 
         \\ =& -\dual{\delta(x-y)}{f'(x)\psi(x)} - \dual{\delta(x-y)}{f(x)\psi'(x)} 
         \\ =& -f'(y) \psi(y) - f(y) \dual{\delta(x-y)}{\psi'(x)} 
         \\ =& - \dual{f'(x)  \delta(x-y)}{\psi(x)} + f(y) \dual{\partial_x \delta(x-y)}{\psi(x)} 
         \\ =& \dual{f(y) \delta(x-y) - f'(x) \partial_x \delta(x-y)}{\psi(x)} \:.
    \end{align*}
    Therefore
    \begin{align}
        \dual{f(y) \partial_x \delta(x-y)}{\psi(x)} = \dual{f'(x) \delta(x-y)}{\psi(x)} + \dual{f(x) \partial_x \delta(x-y)}{\psi(x)} \:.
    \end{align} 
\end{proof}

The convolution of two distributions is not simple to construct in rigorous way. The procedure is the following. First the tensor product of distributions is defined
\begin{align}
    \dual{A(x) \otimes B(y)}{\phi(x,y)} = \dual{A(x)}{\dual{B(y)}{\phi(x,y)}} \:.
\end{align}
The product defined this way satisfies comutativity, associativity and it is indeed a distribution (altough the proof of these properties is non-trivial). Then the convolution of distribution is defined by
\begin{align}
    \dual{A \star B}{\phi(x)} = \dual{A(x) \otimes B(y)}{\phi(x+y)} \:,
\end{align}
with additional requirements on $A \otimes B$ and $\phi$. Convolution defined in this way satisfies associativity and if it exists, then
\begin{align}
    D^\alpha (A \star B) = D^\alpha A \star B = A \star D^\alpha B \:.
\end{align}

The convolution of Dirac distribution and arbitrary distribution $A$ always exists and is equal to
\begin{align}
    A(y) \star \delta(x-y) = A(x) \:.
\end{align}
This means, in particular, that given an integral functional $T[u]$ one can write
\begin{align}
    T[u(x)] = T[u(y)]  \star \delta(x-y)  \:,
\end{align}
or in physicist's notation
\begin{align}
    T[u(x)] = \int \D y \, T[u(y)] \, \delta(x-y) \:. \label{eq:konvoluce-s-deltou}
\end{align}
The equation \eqref{eq:konvoluce-s-deltou} is very important in calculations of functional derivatives.
\begin{example}
    Let $u(x)$ be a field variable and $F[u(x)]$ an integral functional. 
    To compute its functional derivative with respect to $u(y)$ in different position $y$, we use the integral expression of $F$
    \begin{align}
        F[u(x)] = \int \D y F[u(y)] \delta (x-y) \:.
    \end{align}
    Its Gateaux derivative is
    \begin{align}
        \delta F[u,h] = \der{}{t} F[u+th]|_{t=0} = \int \D y \pder{F}{u}(y) \delta(x-y) h(y) \:,
    \end{align}
    therefore
    \begin{align}
        \fder{F(u(x))}{u(y)} = \pder{F}{u}(x) \delta(x-y) \:.
    \end{align}
\end{example}

\begin{example}
    In the special case of performing functional derivative w.r.t. the same field but in the different position,
    \begin{align}
        \fder{u^i(x)}{u^j(y)} = \delta^i_j \delta(x-y) \:,
    \end{align}
    because
    \begin{align}
        \fder{u^i(x)}{u^j(y)} = \fder{}{u^j(y)} \int \D y u^i(y) \delta (x-y) = \pder{u^i}{u^j}(y) \delta (x-y) = \delta^i_j \delta (x-y) \:.
    \end{align}
    The same applies to
    \begin{align}
        \fder{}{u^j(y)} \partial_x u^i(x) = - \delta^i_j \partial_x \delta(x-y) \:,
    \end{align}
    because
    \begin{align}
        \fder{}{u^j(y)} \partial_x u^i(x) = \fder{}{u^j(y)} \int \D y \partial_y u^i(y) \delta(x-y) 
        \\ = -\fder{}{u^j(y)} \int \D y u^i(y) \partial_y \delta(x-y) = - \delta^i_j \partial_x \delta(x-y) \:.
    \end{align}
\end{example}